# Кросс-валидация

- **k-fold cross-validation** (k-блочная кросс-валидация). Этот метод случайным образом разбивает данные на k непересекающихся блоков примерно одинакового размера. Поочередно каждый блок рассматривается, как валидационная выборка, а остальные k-1 блоков – как обучающая выборка. Модель обучается на k-1 блоках и прогнозирует валидационный блок. Прогноз модели оценивается с помощью выбранного показателя (правильность (accuracy), среднеквадратичное отклонение (СКО) и т.п.). Процесс повторяется k раз, и мы получаем k оценок, для которых рассчитывается среднее значение, являющееся итоговой оценкой модели. Обычно k выбирают равным 10, иногда 5. Если k равен количеству элементов в исходном наборе данных, этот метод называется кросс-валидацией по отдельным элементам (leave-one-out cross-validation) (в этой статье не рассматривается).
- **Repeated k-fold cross-validation** (многократная k-блочная кросс-валидация). В рамках этого метода k-блочная кросс-валидация выполняется несколько раз. Например, 5-кратная 10-блочная кросс-валидация даст 50 оценок, на основе которых затем будет рассчитана средняя оценка. Обратите внимание, это не то же самое, что 50-блочная кросс-валидация.
- **МККВ, Monte Carlo cross-validation, leave-group-out cross-validation** (кросс-валидация на основе метода Монте-Карло). Данный метод заданное количество раз случайным образом разбивает исходный набор данных на обучающую и валидационную выборку в заданной пропорции.
- **Bootstrap** (бутстреп). Аналогичен кросс-валидации на основе метода Монте-Карло, за исключением того, что формирование обучающей выборки осуществляется с возвращением (with replacement) элементов. Это означает, что в данной обучающей выборке один и тот же элемент может встречаться несколько раз. Соответственно, некоторые элементы могут вообще не встречаться в обучающей выборке. Модель обучается на обучающей выборке, а данные, не вошедшие в обучающую выборку, используются для валидации. 

Основное отличие MMKB от k-блочной кросс-валидации состоит в том, что блочная валидация  разбивает исходный набор данных на непересекающиеся блоки, в то время как МККВ каждый раз выполняет случайное разбиение. Поэтому в МККВ некоторый элемент данных может встречаться в нескольких выборках. 

> _При увеличении числа разбиений уменьшается число объектов в выборке и растет дисперсия результата. При уменьшении числа разбиений падает точность результата (растет смещение). Уменьшению дисперсии способствует многократная кросс-валидация._

> _Есть результаты исследований. что наилучшие результаты дает  многократная 10-блочная кросс-валидация. При большом объеме выборок хорошие результаты может дать однократная 10-блочная или даже 5-блочная валидация. [Сравнение различных видов кросс-валидации]._

## k-блочная кросс-валидация в Python
Формирует заданное количество наборов train / test выборок, последовательно возвращая функцией split() наборы индексов для обучающей и тестовой выборок.
Реализация: `sklearn.model_selection.KFold`
```python
from numpy import array
from sklearn.model_selection import KFold

data = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])                  ; data sample
kfold = KFold(3, True, 1)                                     ; prepare cross validation
for train, test in kfold.split(data):                         ; enumerate splits
    print('train: %s, test: %s' % (data[train], data[test]))
```
